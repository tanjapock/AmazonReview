{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0ef487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4f8a67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_minhashing=pd.read_csv(\"/Users/madalena/Desktop/minhashing_results_subset.csv\")\n",
    "df=data_minhashing\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3b4e076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['signature', 'rating'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81db87a",
   "metadata": {},
   "source": [
    "## CLUSTER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0769de78",
   "metadata": {},
   "source": [
    "DBSCAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7edf9ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (500000, 100)\n"
     ]
    }
   ],
   "source": [
    "# == 1. Convert stringified signatures into numeric arrays\n",
    "if isinstance(df['signature'].iloc[0], str):\n",
    "    df['signature'] = df['signature'].apply(lambda s: np.fromstring(s.strip('[]'), sep=' '))\n",
    "\n",
    "# Build feature matrix\n",
    "X = np.vstack(df['signature'].values)\n",
    "print(\"Feature matrix shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d8f610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA reduced shape: (500000, 50)\n",
      "Explained variance ratio sum: 0.76\n"
     ]
    }
   ],
   "source": [
    "# === 2. Dimensionality reduction with PCA ===\n",
    "pca = PCA(n_components=50, random_state=42)  # keep 90% of variance\n",
    "X_reduced = pca.fit_transform(X)\n",
    "print(f\"PCA reduced shape: {X_reduced.shape}\")\n",
    "print(f\"Explained variance ratio sum: {np.sum(pca.explained_variance_ratio_):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dca675f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'umap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 3 - IF I WANT UMAP\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mumap\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UMAP\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m umap_model = umap.UMAP(\n\u001b[32m      5\u001b[39m     n_neighbors=\u001b[32m30\u001b[39m,      \u001b[38;5;66;03m# controls local vs global structure\u001b[39;00m\n\u001b[32m      6\u001b[39m     min_dist=\u001b[32m0.0\u001b[39m,        \u001b[38;5;66;03m# tighter clusters\u001b[39;00m\n\u001b[32m      7\u001b[39m     n_components=\u001b[32m5\u001b[39m,      \u001b[38;5;66;03m# 2–10 recommended\u001b[39;00m\n\u001b[32m      8\u001b[39m     metric=\u001b[33m'\u001b[39m\u001b[33meuclidean\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      9\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m X_umap = umap_model.fit_transform(X_pca)\n",
      "\u001b[31mNameError\u001b[39m: name 'umap' is not defined"
     ]
    }
   ],
   "source": [
    "# 3 - IF I WANT UMAP\n",
    "from umap import UMAP\n",
    "\n",
    "umap_model = umap.UMAP(\n",
    "    n_neighbors=30,      # controls local vs global structure\n",
    "    min_dist=0.0,        # tighter clusters\n",
    "    n_components=5,      # 2–10 recommended\n",
    "    metric='euclidean',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_umap = umap_model.fit_transform(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1389ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale PCA features  AFTER UMAP\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_umap_scaled = StandardScaler().fit_transform(X_umap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebedabd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - scale PCA features WITHOUT UMAP\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaled = StandardScaler().fit_transform(X_reduced) #(might do X_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "183b52ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WITHOUT PRE CLUSTER\n",
    "# To choose Eps:\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Use k=2 because the first neighbor is the point itself\n",
    "nbrs = NearestNeighbors(n_neighbors=2).fit(X_reduced)\n",
    "distances, indices = nbrs.kneighbors(X_reduced)\n",
    "\n",
    "# Take distance to the nearest neighbor (excluding itself)\n",
    "nearest_dist = np.sort(distances[:,1])  # skip distance to self\n",
    "#plt.plot(nearest_dist)\n",
    "#plt.ylabel(\"Distance to nearest neighbor\")\n",
    "#plt.xlabel(\"Points sorted by distance\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3a70f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2736197532.5903726\n"
     ]
    }
   ],
   "source": [
    "eps = np.percentile(nearest_dist, 95)\n",
    "print(eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3284d4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "eps = 2e10 # <-- adjust after checking the curve\n",
    "min_samples = 15\n",
    "\n",
    "# --- 3. Run DBSCAN on the post PCA Data ---\n",
    "dbscan = DBSCAN(eps=eps, min_samples=min_samples, metric='euclidean')\n",
    "clusters = dbscan.fit_predict(X_umap_scaled)\n",
    "print(\"DBSCAN cluster labels distribution:\")\n",
    "unique, counts = np.unique(clusters, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58759ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (10000, 100)\n"
     ]
    }
   ],
   "source": [
    "# WITH SUBSAMPLE FIRST\n",
    "# pick e.g. 10,000 points for DBSCAN (adjust if needed)\n",
    "subset_size = 10000\n",
    "indices_sub = np.random.choice(len(X_scaled), size=subset_size, replace=False)\n",
    "\n",
    "X_sub = X_scaled[indices_sub]\n",
    "print(\"Feature matrix shape:\", X_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77067f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated eps: 16.775164718596564\n"
     ]
    }
   ],
   "source": [
    "#WITH SUBSAMPLE FIRST\n",
    "nbrs = NearestNeighbors(n_neighbors=2).fit(X_sub)\n",
    "distances, _ = nbrs.kneighbors(X_sub)\n",
    "nearest_dist = np.sort(distances[:,1])\n",
    "\n",
    "# Pick eps as the 95th percentile\n",
    "eps = np.percentile(nearest_dist, 95)\n",
    "print(\"Estimated eps:\", eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f05985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentile 60, eps=5.5899 {np.int64(-1): np.int64(4030), np.int64(0): np.int64(5970)}\n",
      "Percentile 70, eps=7.1167 {np.int64(-1): np.int64(3029), np.int64(0): np.int64(6971)}\n",
      "Percentile 80, eps=9.5547 {np.int64(-1): np.int64(2023), np.int64(0): np.int64(7977)}\n",
      "Percentile 85, eps=11.4382 {np.int64(-1): np.int64(1525), np.int64(0): np.int64(8475)}\n",
      "Percentile 90, eps=13.5394 {np.int64(-1): np.int64(1021), np.int64(0): np.int64(8979)}\n",
      "Percentile 95, eps=16.7752 {np.int64(-1): np.int64(510), np.int64(0): np.int64(9490)}\n"
     ]
    }
   ],
   "source": [
    "#To check what is going on with the code - Seems like its aone big cluster and without UMAP, DBSCAN wont work\n",
    "for p in [60, 70, 80, 85, 90, 95]:\n",
    "    eps_test = np.percentile(nearest_dist, p)\n",
    "    db_test = DBSCAN(eps=eps_test, min_samples=20).fit_predict(X_sub)\n",
    "    unique, counts = np.unique(db_test, return_counts=True)\n",
    "    print(f\"Percentile {p}, eps={eps_test:.4f}\", dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1335cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster distribution on subset: {np.int64(-1): np.int64(1019), np.int64(0): np.int64(8981)}\n"
     ]
    }
   ],
   "source": [
    "#Running DBSCAN in the subsample\n",
    "min_samples = 20\n",
    "db = DBSCAN(eps=eps, min_samples=min_samples, metric='euclidean')\n",
    "labels_sub = db.fit_predict(X_sub)\n",
    "\n",
    "# Print cluster distribution\n",
    "unique, counts = np.unique(labels_sub, return_counts=True)\n",
    "print(\"Cluster distribution on subset:\", dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df45149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e218db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madalena/miniforge3/lib/python3.12/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/madalena/miniforge3/lib/python3.12/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Run HDBSCAN\n",
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=50,  # smallest allowed cluster\n",
    "    min_samples=20,       # density threshold, optional\n",
    "    cluster_selection_method='eom'\n",
    ")\n",
    "\n",
    "labels = clusterer.fit_predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3702a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e3307e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster distribution: {np.int64(-1): np.int64(500000)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Check cluster distribution\n",
    "import numpy as np\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "print(\"Cluster distribution:\", dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4283f90d",
   "metadata": {},
   "source": [
    "## EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b113ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATION using DAVIES-BOULDIN INDEX\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "# --- 3. Evaluate with Davies-Bouldin Index ---\n",
    "db = davies_bouldin_score(X, clusters)\n",
    "print(f\"Davies-Bouldin Index (DB): {db:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68050bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT in two dimensions using PCA and color by cluster\n",
    "#prepare data \n",
    "X = np.array(df['signature'].tolist())  # shape (n_samples, 100)\n",
    "# --- 4. Optional: visualize clusters ---\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='tab10', alpha=0.7)\n",
    "plt.title(\"K-Means clustering of MinHash signatures\")\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "plt.colorbar(label=\"Cluster ID\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
